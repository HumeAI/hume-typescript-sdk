/**
 * This file was auto-generated by Fern from our API Definition.
 */
import * as environments from "../../../../../../environments";
import * as core from "../../../../../../core";
import * as Hume from "../../../../../index";
import * as stream from "stream";
export declare namespace Batch {
    interface Options {
        environment?: core.Supplier<environments.HumeEnvironment | string>;
        /** Specify a custom URL to connect the client to. */
        baseUrl?: core.Supplier<string>;
        apiKey?: core.Supplier<string | undefined>;
        /** Additional headers to include in requests. */
        headers?: Record<string, string | core.Supplier<string | undefined> | undefined>;
        fetcher?: core.FetchFunction;
    }
    interface RequestOptions {
        /** The maximum time to wait for a response in seconds. */
        timeoutInSeconds?: number;
        /** The number of times to retry the request. Defaults to 2. */
        maxRetries?: number;
        /** A hook to abort the request. */
        abortSignal?: AbortSignal;
        /** Additional headers to include in the request. */
        headers?: Record<string, string | core.Supplier<string | undefined> | undefined>;
    }
}
export declare class Batch {
    protected readonly _options: Batch.Options;
    constructor(_options?: Batch.Options);
    /**
     * Sort and filter jobs.
     *
     * @param {Hume.expressionMeasurement.batch.BatchListJobsRequest} request
     * @param {Batch.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.expressionMeasurement.batch.listJobs()
     */
    listJobs(
        request?: Hume.expressionMeasurement.batch.BatchListJobsRequest,
        requestOptions?: Batch.RequestOptions,
    ): core.HttpResponsePromise<Hume.expressionMeasurement.batch.UnionJob[]>;
    private __listJobs;
    /**
     * Start a new measurement inference job.
     *
     * @param {Hume.expressionMeasurement.batch.InferenceBaseRequest} request
     * @param {Batch.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.expressionMeasurement.batch.startInferenceJob({
     *         urls: ["https://hume-tutorials.s3.amazonaws.com/faces.zip"],
     *         notify: true
     *     })
     */
    startInferenceJob(
        request: Hume.expressionMeasurement.batch.InferenceBaseRequest,
        requestOptions?: Batch.RequestOptions,
    ): core.HttpResponsePromise<Hume.expressionMeasurement.batch.JobId>;
    private __startInferenceJob;
    /**
     * Get the request details and state of a given job.
     *
     * @param {string} id - The unique identifier for the job.
     * @param {Batch.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.expressionMeasurement.batch.getJobDetails("job_id")
     */
    getJobDetails(
        id: string,
        requestOptions?: Batch.RequestOptions,
    ): core.HttpResponsePromise<Hume.expressionMeasurement.batch.UnionJob>;
    private __getJobDetails;
    /**
     * Get the JSON predictions of a completed inference job.
     *
     * @param {string} id - The unique identifier for the job.
     * @param {Batch.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.expressionMeasurement.batch.getJobPredictions("job_id")
     */
    getJobPredictions(
        id: string,
        requestOptions?: Batch.RequestOptions,
    ): core.HttpResponsePromise<Hume.expressionMeasurement.batch.UnionPredictResult[]>;
    private __getJobPredictions;
    /**
     * Get the artifacts ZIP of a completed inference job.
     */
    getJobArtifacts(id: string, requestOptions?: Batch.RequestOptions): core.HttpResponsePromise<stream.Readable>;
    private __getJobArtifacts;
    /**
     * Start a new batch inference job.
     *
     * @param {core.FileLike[]} file
     * @param {Hume.expressionMeasurement.batch.BatchStartInferenceJobFromLocalFileRequest} request
     * @param {Batch.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.expressionMeasurement.batch.startInferenceJobFromLocalFile([fs.createReadStream("/path/to/your/file")], {})
     */
    startInferenceJobFromLocalFile(
        file: core.FileLike[],
        request: Hume.expressionMeasurement.batch.BatchStartInferenceJobFromLocalFileRequest,
        requestOptions?: Batch.RequestOptions,
    ): core.HttpResponsePromise<Hume.expressionMeasurement.batch.JobId>;
    private __startInferenceJobFromLocalFile;
    protected _getCustomAuthorizationHeaders(): Promise<{
        "X-Hume-Api-Key": string | undefined;
    }>;
}
