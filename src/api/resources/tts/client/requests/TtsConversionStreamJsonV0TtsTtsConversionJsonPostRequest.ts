/**
 * This file was auto-generated by Fern from our API Definition.
 */

/**
 * @example
 *     {
 *         accessToken: "access_token"
 *     }
 */
export interface TtsConversionStreamJsonV0TtsTtsConversionJsonPostRequest {
    /**
     * Access token used for authenticating the client. If not provided, an `api_key` must be provided to authenticate.
     *
     * The access token is generated using both an API key and a Secret key, which provides an additional layer of security compared to using just an API key.
     *
     * For more details, refer to the [Authentication Strategies Guide](/docs/introduction/api-key#authentication-strategies).
     */
    accessToken?: string;
    /** The TTS model to use for speech generations. */
    model?: "octave";
    version?: unknown;
    /** The ID of a prior TTS generation to use as context for generating consistent speech style and prosody across multiple requests. Including context may increase audio generation times. */
    contextGenerationId?: string;
    /** The input text to be converted to speech output. */
    contextUtterancesNText?: string;
    /** Natural language instructions describing how the text should be spoken by the model (e.g., `"a soft, gentle voice with a strong British accent"`). */
    contextUtterancesNDescription?: string;
    /** ID of the voice in the `Voice Library`. */
    contextUtterancesNVoiceId?: string;
    contextUtterancesNVoiceProvider?: unknown;
    /** Name of the voice in the `Voice Library`. */
    contextUtterancesNVoiceName?: string;
    /** A relative measure of how fast this utterance should be spoken. */
    contextUtterancesNSpeed?: number;
    /** Duration of trailing silence (in seconds) to add to this utterance */
    contextUtterancesNTrailingSilence?: number;
    /** The input text to be converted to speech output. */
    utterancesNText?: string;
    /** Natural language instructions describing how the text should be spoken by the model (e.g., `"a soft, gentle voice with a strong British accent"`). */
    utterancesNDescription?: string;
    /** ID of the voice in the `Voice Library`. */
    utterancesNVoiceId?: string;
    utterancesNVoiceProvider?: unknown;
    /** Name of the voice in the `Voice Library`. */
    utterancesNVoiceName?: string;
    /** A relative measure of how fast this utterance should be spoken. */
    utterancesNSpeed?: number;
    /** Duration of trailing silence (in seconds) to add to this utterance */
    utterancesNTrailingSilence?: number;
    /** Number of generations of the audio to produce. */
    numGenerations?: number;
    /** Format for the output audio. */
    formatType?: "mp3";
    /** If enabled, enhances the provided description prompt to improve voice generation quality. */
    expandDescription?: boolean;
    /** If enabled, each input utterance will be split as needed into more natural-sounding `snippets` of speech for audio generation. */
    splitUtterances?: boolean;
    /** If enabled, additional generations will be made, and the best `num_generations` of them all will be returned. */
    filterGenerations?: boolean;
    /** If enabled, consecutive utterances with the different voices will be generated with compounding context that takes into account the previous utterances. */
    multiSpeaker?: boolean;
    /** If enabled, the audio for all the chunks of a generation, once concatenated together, will constitute a single audio file. Otherwise, if disabled, each chunk's audio will be its own audio file, each with its own headers (if applicable). */
    stripHeaders?: boolean;
    includeTimestampTypesN?: unknown;
    /** If enabled, no binary websocket messages will be sent to the client. */
    noBinary?: boolean;
    /** Accelerates processing to reduce streaming latency. Incurs approximately 10% additional cost while preserving full voice quality. */
    instantMode?: boolean;
}
