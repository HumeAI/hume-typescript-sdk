// This file was auto-generated by Fern from our API Definition.

import type * as core from "../../../../../core/index.js";
import type * as Hume from "../../../../index.js";

/**
 * @example
 *     {
 *         accessToken: "access_token"
 *     }
 */
export interface TtsConversionStreamFileV0TtsStreamFileMultipartPostRequest {
    /**
     * Access token used for authenticating the client. If not provided, an `api_key` must be provided to authenticate.
     *
     * The access token is generated using both an API key and a Secret key, which provides an additional layer of security compared to using just an API key.
     *
     * For more details, refer to the [Authentication Strategies Guide](/docs/introduction/api-key#authentication-strategies).
     */
    accessToken?: string;
    /** The ID of a prior TTS generation to use as context for generating consistent speech style and prosody across multiple requests. Including context may increase audio generation times. */
    contextGenerationId?: string;
    /**
     * Natural language instructions describing how the synthesized speech should sound, including but not limited to tone, intonation, pacing, and accent.
     *
     * **This field behaves differently depending on whether a voice is specified**:
     * - **Voice specified**: the description will serve as acting directions for delivery. Keep directions concise—100 characters or fewer—for best results. See our guide on [acting instructions](/docs/text-to-speech-tts/acting-instructions).
     * - **Voice not specified**: the description will serve as a voice prompt for generating a voice. See our [prompting guide](/docs/text-to-speech-tts/prompting) for design tips.
     */
    contextUtterancesNDescription?: string;
    /** Speed multiplier for the synthesized speech. Extreme values below 0.75 and above 1.5 may sometimes cause instability to the generated output. */
    contextUtterancesNSpeed?: number;
    /** The input text to be synthesized into speech. */
    contextUtterancesNText?: string;
    /** Duration of trailing silence (in seconds) to add to this utterance */
    contextUtterancesNTrailingSilence?: number;
    /** The unique ID associated with the **Voice**. */
    contextUtterancesNVoiceId?: string;
    /** The name of a **Voice**. */
    contextUtterancesNVoiceName?: string;
    /**
     * Specifies the source provider associated with the chosen voice.
     *
     * - **`HUME_AI`**: Select voices from Hume's [Voice Library](https://app.hume.ai/tts/voice-library), containing a variety of preset, shared voices.
     * - **`CUSTOM_VOICE`**: Select from voices you've personally generated and saved in your account.
     *
     * If no provider is explicitly set, the default provider is `CUSTOM_VOICE`. When using voices from Hume's **Voice Library**, you must explicitly set the provider to `HUME_AI`.
     *
     * Preset voices from Hume's **Voice Library** are accessible by all users. In contrast, your custom voices are private and accessible only via requests authenticated with your API key.
     */
    contextUtterancesNVoiceProvider?: Hume.tts.VoiceProvider;
    /** If enabled, enhances the provided description prompt to improve voice generation quality. */
    expandDescription?: boolean;
    /** If enabled, additional generations will be made, and the best `num_generations` of them all will be returned. */
    filterGenerations?: boolean;
    /** Format for the output audio. */
    formatType?: "mp3";
    /** The set of timestamp types to include in the response. Only supported for Octave 2 requests. */
    includeTimestampTypesN?: Hume.tts.TimestampType;
    /**
     * Enables ultra-low latency streaming, significantly reducing the time until the first audio chunk is received. Recommended for real-time applications requiring immediate audio playback. For further details, see our documentation on [instant mode](/docs/text-to-speech-tts/overview#ultra-low-latency-streaming-instant-mode).
     * - A [voice](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.utterances.voice) must be specified when instant mode is enabled. Dynamic voice generation is not supported with this mode.
     * - Instant mode is only supported for streaming endpoints (e.g., [/v0/tts/stream/json](/reference/text-to-speech-tts/synthesize-json-streaming), [/v0/tts/stream/file](/reference/text-to-speech-tts/synthesize-file-streaming)).
     * - Ensure only a single generation is requested ([num_generations](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.num_generations) must be `1` or omitted).
     */
    instantMode?: boolean;
    /** The TTS model to use for speech generations. */
    model?: "octave";
    /** If enabled, consecutive utterances with the different voices will be generated with compounding context that takes into account the previous utterances. */
    multiSpeaker?: boolean;
    /** If enabled, no binary websocket messages will be sent to the client. */
    noBinary?: boolean;
    /**
     * Number of audio generations to produce from the input utterances.
     *
     * Using `num_generations` enables faster processing than issuing multiple sequential requests. Additionally, specifying `num_generations` allows prosody continuation across all generations without repeating context, ensuring each generation sounds slightly different while maintaining contextual consistency.
     */
    numGenerations?: number;
    /**
     * Controls how audio output is segmented in the response.
     *
     * - When **enabled** (`true`), input utterances are automatically split into natural-sounding speech segments.
     *
     * - When **disabled** (`false`), the response maintains a strict one-to-one mapping between input utterances and output snippets.
     *
     * This setting affects how the `snippets` array is structured in the response, which may be important for applications that need to track the relationship between input text and generated audio segments. When setting to `false`, avoid including utterances with long `text`, as this can result in distorted output.
     */
    splitUtterances?: boolean;
    /** If enabled, the audio for all the chunks of a generation, once concatenated together, will constitute a single audio file. Otherwise, if disabled, each chunk's audio will be its own audio file, each with its own headers (if applicable). */
    stripHeaders?: boolean;
    /** Reference audio to use for voice conversion for this utterance. */
    utterancesNAudio?: core.file.Uploadable | undefined;
    /**
     * Natural language instructions describing how the synthesized speech should sound, including but not limited to tone, intonation, pacing, and accent.
     *
     * **This field behaves differently depending on whether a voice is specified**:
     * - **Voice specified**: the description will serve as acting directions for delivery. Keep directions concise—100 characters or fewer—for best results. See our guide on [acting instructions](/docs/text-to-speech-tts/acting-instructions).
     * - **Voice not specified**: the description will serve as a voice prompt for generating a voice. See our [prompting guide](/docs/text-to-speech-tts/prompting) for design tips.
     */
    utterancesNDescription?: string;
    /** Speed multiplier for the synthesized speech. Extreme values below 0.75 and above 1.5 may sometimes cause instability to the generated output. */
    utterancesNSpeed?: number;
    /** The input text to be synthesized into speech. */
    utterancesNText?: string;
    /** Duration of trailing silence (in seconds) to add to this utterance */
    utterancesNTrailingSilence?: number;
    /** The unique ID associated with the **Voice**. */
    utterancesNVoiceId?: string;
    /** The name of a **Voice**. */
    utterancesNVoiceName?: string;
    /**
     * Specifies the source provider associated with the chosen voice.
     *
     * - **`HUME_AI`**: Select voices from Hume's [Voice Library](https://app.hume.ai/tts/voice-library), containing a variety of preset, shared voices.
     * - **`CUSTOM_VOICE`**: Select from voices you've personally generated and saved in your account.
     *
     * If no provider is explicitly set, the default provider is `CUSTOM_VOICE`. When using voices from Hume's **Voice Library**, you must explicitly set the provider to `HUME_AI`.
     *
     * Preset voices from Hume's **Voice Library** are accessible by all users. In contrast, your custom voices are private and accessible only via requests authenticated with your API key.
     */
    utterancesNVoiceProvider?: Hume.tts.VoiceProvider;
    /**
     * Selects the Octave model version used to synthesize speech for this request. If you omit this field, Hume automatically routes the request to the most appropriate model. Setting a specific version ensures stable and repeatable behavior across requests.
     *
     * Use `2` to opt into the latest Octave capabilities. When you specify version `2`, you must also provide a `voice`. Requests that set `version: 2` without a voice will be rejected.
     *
     * For a comparison of Octave versions, see the [Octave versions](/docs/text-to-speech-tts/overview#octave-versions) section in the TTS overview.
     */
    version?: Hume.tts.OctaveVersion;
}
