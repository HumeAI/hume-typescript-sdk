/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as Hume from "../../../index.js";

/**
 * A description of a single event in a chat returned from the server
 */
export interface ReturnChatEvent {
    /** Identifier for a Chat Event. Formatted as a UUID. */
    id: string;
    /** Identifier for the Chat this event occurred in. Formatted as a UUID. */
    chatId: string;
    /** Time at which the Chat Event occurred. Measured in seconds since the Unix epoch. */
    timestamp: number;
    /**
     * The role of the entity which generated the Chat Event. There are four possible values:
     * - `USER`: The user, capable of sending user messages and interruptions.
     * - `AGENT`: The assistant, capable of sending agent messages.
     * - `SYSTEM`: The backend server, capable of transmitting errors.
     * - `TOOL`: The function calling mechanism.
     */
    role: Hume.empathicVoice.ReturnChatEventRole;
    /**
     * Type of Chat Event. There are eleven Chat Event types:
     * - `SYSTEM_PROMPT`: The system prompt used to initialize the session.
     * - `CHAT_START_MESSAGE`: Marks the beginning of the chat session.
     * - `USER_RECORDING_START_MESSAGE`: Marks when the client began streaming audio and the start of audio processing.
     * - `USER_MESSAGE`: A message sent by the user.
     * - `USER_INTERRUPTION`: A user-initiated interruption while the assistant is speaking.
     * - `AGENT_MESSAGE`: A response generated by the assistant.
     * - `FUNCTION_CALL`: A record of a tool invocation by the assistant.
     * - `FUNCTION_CALL_RESPONSE`: The result of a previously invoked function or tool.
     * - `PAUSE_ONSET`: Marks when the client sent a `pause_assistant_message` to pause the assistant.
     * - `RESUME_ONSET`: Marks when the client sent a `resume_assistant_message` to resume the assistant.
     * - `CHAT_END_MESSAGE`: Indicates the end of the chat session.
     */
    type: Hume.empathicVoice.ReturnChatEventType;
    /** The text of the Chat Event. This field contains the message content for each event type listed in the `type` field. */
    messageText?: string;
    /**
     * Stringified JSON containing the prosody model inference results.
     *
     * EVI uses the prosody model to measure 48 expressions related to speech and vocal characteristics. These results contain a detailed emotional and tonal analysis of the audio. Scores typically range from 0 to 1, with higher values indicating a stronger confidence level in the measured attribute.
     */
    emotionFeatures?: string;
    /** Stringified JSON with additional metadata about the chat event. */
    metadata?: string;
}
