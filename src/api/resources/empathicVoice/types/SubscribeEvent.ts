// This file was auto-generated by Fern from our API Definition.

import type * as Hume from "../../../index.js";

export type SubscribeEvent =
    /**
     * **Indicates the conclusion of the assistant's response**, signaling that the assistant has finished speaking for the current conversational turn. */
    | Hume.empathicVoice.AssistantEnd
    /**
     * **Transcript of the assistant's message.** Contains the message role, content, and optionally tool call information including the tool name, parameters, response requirement status, tool call ID, and tool type. */
    | Hume.empathicVoice.AssistantMessage
    /**
     * **Expression measurement predictions of the assistant's audio output.** Contains inference model results including prosody scores for 48 emotions within the detected expression of the assistant's audio sample. */
    | Hume.empathicVoice.AssistantProsody
    /**
     * **Base64 encoded audio output.** This encoded audio is transmitted to the client, where it can be decoded and played back as part of the user interaction. The returned audio format is WAV and the sample rate is 48kHz.
     *
     * Contains the audio data, an ID to track and reference the audio output, and an index indicating the chunk position relative to the whole audio segment. See our [Audio Guide](/docs/speech-to-speech-evi/guides/audio) for more details on preparing and processing audio. */
    | Hume.empathicVoice.AudioOutput
    /**
     * **The first message received after establishing a connection with EVI**, containing important identifiers for the current Chat session.
     *
     * Includes the Chat ID (which allows the Chat session to be tracked and referenced) and the Chat Group ID (used to resume a Chat when passed in the `resumed_chat_group_id` query parameter of a subsequent connection request, allowing EVI to continue the conversation from where it left off within the Chat Group). */
    | Hume.empathicVoice.ChatMetadata
    /**
     * **Indicates a disruption in the WebSocket connection**, such as an unexpected disconnection, protocol error, or data transmission issue.
     *
     * Contains an error code identifying the type of error encountered, a detailed description of the error, and a short, human-readable identifier and description (slug) for the error. */
    | Hume.empathicVoice.WebSocketError
    /**
     * **Indicates the user has interrupted the assistant's response.** EVI detects the interruption in real-time and sends this message to signal the interruption event.
     *
     * This message allows the system to stop the current audio playback, clear the audio queue, and prepare to handle new user input. Contains a Unix timestamp of when the user interruption was detected. For more details, see our [Interruptibility Guide](/docs/speech-to-speech-evi/features/interruptibility) */
    | Hume.empathicVoice.UserInterruption
    /**
     * **Transcript of the user's message.** Contains the message role and content, along with a `from_text` field indicating if this message was inserted into the conversation as text from a `UserInput` message.
     *
     * Includes an `interim` field indicating whether the transcript is provisional (words may be repeated or refined in subsequent `UserMessage` responses as additional audio is processed) or final and complete. Interim transcripts are only sent when the `verbose_transcription` query parameter is set to true in the initial handshake. */
    | Hume.empathicVoice.UserMessage
    /**
     * **Indicates that the supplemental LLM has detected a need to invoke the specified tool.** This message is only received for user-defined function tools.
     *
     * Contains the tool name, parameters (as a stringified JSON schema), whether a response is required from the developer (either in the form of a `ToolResponseMessage` or a `ToolErrorMessage`), the unique tool call ID for tracking the request and response, and the tool type. See our [Tool Use Guide](/docs/speech-to-speech-evi/features/tool-use) for further details. */
    | Hume.empathicVoice.ToolCallMessage
    /**
     * **Return value of the tool call.** Contains the output generated by the tool to pass back to EVI. Upon receiving a Tool Call message and successfully invoking the function, this message is sent to convey the result of the function call back to EVI.
     *
     * For built-in tools implemented on the server, you will receive this message type rather than a `ToolCallMessage`. See our [Tool Use Guide](/docs/speech-to-speech-evi/features/tool-use) for further details. */
    | Hume.empathicVoice.ToolResponseMessage
    /**
     * **Error message from the tool call**, not exposed to the LLM or user. Upon receiving a Tool Call message and failing to invoke the function, this message is sent to notify EVI of the tool's failure.
     *
     * For built-in tools implemented on the server, you will receive this message type rather than a `ToolCallMessage` if the tool fails. See our [Tool Use Guide](/docs/speech-to-speech-evi/features/tool-use) for further details. */
    | Hume.empathicVoice.ToolErrorMessage;
